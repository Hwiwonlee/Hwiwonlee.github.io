---
title: "Machine Learning with R"
author: "Hwiwon Lee"
date: "`r format(Sys.Date())`"
categories:
  - Machine Learning
  - Book
tags:
  - R
  - Machine Learning
output: 
  # https://blog.zarathu.com/posts/2019-01-03-rmarkdown/
    bookdown::html_document2:
      number_sections: FALSE
      fig_caption: TRUE
      fig_height: 6
      fig_width: 10
      highlight: textmate
      theme: cosmo
      toc: yes
      toc_depth: 4
      toc_float: yes
      css: "post_style.css"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.height = 8, fig.align = "center", cache=T, dpi = 300, dev = "png",
                      comment = "#>")

# https://tibble.tidyverse.org/reference/formatting.html
options(tibble.print_max = 10)
options(tibble.max_extra_cols = 5)
# options(max.print = 300)

library(knitr) # for include_graphics()
library(tidyverse) # as you known, core package
library(googledrive) # Import dataset from the google drive
library(readr) # To read csv file
library(foreign)
library(caret)
library(showtext)
font_add_google('Noto Sans KR', 'notosanskr')
font_add_google('Noto Sans', 'notosans')
font_add_google('Nanum Gothic', 'nanumgothic')

```

# 3장 게으른 학습 : 최근접 이웃을 사용한 분류(Lazy Learning : Classification with KNN Method)

3장에서는 [위스콘신 유방암 진단 데이터셋](http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/)을 대상으로 [K-Nearest Neighbors algorithm](https://ko.wikipedia.org/wiki/K-%EC%B5%9C%EA%B7%BC%EC%A0%91_%EC%9D%B4%EC%9B%83_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)(KNN, K-최근접 이웃 방법)를 이용한 분류에 대해 다루고 있다.  

머신러닝을 시작할 때, KNN으로 시작하는 경우가 많은데 아무래도 분포나 통계적인 개념들보다 **거리**같은 다소 익숙한 수치(metric)으로 접근 가능하기 때문이 아닌가 생각한다. 그러나 위의 위키피디아 링크를 보면 사실 KNN도 그렇게 쉬운 알고리즘은 아니다. 

이 포스트는 KNN에 대한 이론적인 접근보다는 R에서 KNN을 어떻게 사용하는지에 집중하는 책의 내용처럼 **R에서 KNN을 어떻게 사용할 것인가**를 주로 다룰 것이다. 더하여, 책에서 다루지 않은 **caret 패키지**를 이용한 KNN과 결과의 시각화를 연습해보는 것에 그 목적을 두고 있다. 

## 3.1 WDBC 데이터셋 
[위스콘신 유방암 진단 데이터셋](http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/)에서 받을 수 있는 데이터셋은 `breast-cancer-wisconsin`, `wdbc`(Wisconsin Diagnostic Breast Cancer), `wpbc`(Wisconsin Prognostic Breast Cancer) 등, 총 3개며 각각의 index에 데이터셋의 간단한 설명이 있다. 

R을 활용한 머신러닝에서 사용된 데이터셋은 `wdbc`로 종양에서 진단 혹은 측정할 수 있는 대한 10개의 항목에 대한 평균, 표준 오차, 최댓값을 포함하고 있으며 진단 결과 양성인지 악성인지에 대한 정보 또한 갖고 있다. 따라서 `wdbc`는 `id`를 포함한 32개의 feature를 갖는다. 

사소한 문제 중 하나는 위의 [위스콘신 유방암 진단 데이터셋](http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/)에서 받을 수 있는 `wdbc`에는 feature 이름이 빠져 있다는 것이다. 다행히도 [구글링](https://resources.oreilly.com/examples/9781784393908/blob/ac9fe41596dd42fc3877cfa8ed410dd346c43548/Machine%20Learning%20with%20R,%20Second%20Edition_Code/Chapter%2003/wisc_bc_data.csv)(R을 활용한 머신러닝 2판의 저장소)을 통해 알맞는 이름이 붙여진 데이터셋을 쉽게 구할 수 있다. 

```{r, echo=FALSE, include=FALSE}
drive_auth()
data_in_drive <- drive_find(type = "csv", pattern = "wdbc")

for(i in 1:1){ 
  drive_download(file = data_in_drive$name[i], path = data_in_drive$name[i], overwrite = TRUE)
}
```

```{r}
wdbc <- read_csv("wdbc.csv", col_names = TRUE)
wdbc
```
569x32를 가진 `wdbc`를 성공적으로 불러왔다. **거리**를 사용하는 KNN 알고리즘은 feature들의 표준화가 매우 중요하므로 `preProcess()`를 이용해 centering과 scaling을 해보자. 

## 3.2 머신러닝을 위한 전처리
이번 KNN 예제에서는 train, test set으로 나누는 것과 centering, scaling 변환을 이용해 데이터셋 전처리를 해보겠다.
```{r data partition to train and test set using caret pacakge}
set.seed(1234)

# createDataPartition()를 이용해 75:25로 train, test 나누기 
indextrain <- createDataPartition(y = wdbc$diagnosis,
                                  p = 0.75,
                                  list = FALSE)
# train, test 선언 
# id column은 제외한다. 
train <- wdbc[indextrain, -1]
test <- wdbc[-indextrain, -1]
```

`createDataPartition()`로 dataset split을 진행하면 train, test에 포함될 종속변수의 비율을 원래의 데이터셋과 최대한 같게 유지시켜주기 때문에 train, test set 사이에 발생할 수도 있는 종속변수의 불균형에 대해 신경쓰지 않아도 된다는 장점이 있다. 

```{r, collapse=TRUE}
# train set의 diagnosis 비율
train %>% 
  count(diagnosis) %>% 
  mutate(n = n/nrow(train))

# test set의 diagnosis 비율
test %>% 
  count(diagnosis) %>% 
  mutate(n = n/nrow(test))

# wdbc의 diagnosis 비율
wdbc %>% 
  count(diagnosis) %>% 
  mutate(n = n/nrow(wdbc))
```


```{r centering and scaling with preProcess()}
prep <- preProcess(train, method = c("center", "scale"))

train_st <- predict(prep, train)
test_st <- predict(prep, test)

```
